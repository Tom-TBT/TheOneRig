{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp eyetrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.test import test_eq\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-accessory",
   "metadata": {},
   "source": [
    "# Eye tracking \n",
    "> Ensemble of functions aimed to compensate for the mouse eye motions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import scipy.interpolate as interpolate\n",
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def interpolate_screen_pos(screen_pos, xnew, ynew, kind='linear'):\n",
    "    \"\"\"\n",
    "    Interpolate the position of the xnew and ynew pixels from the original screen_pos.\n",
    "    `interpolate_checker_pos` should be used instead as it's more user friendly.\n",
    "    params:\n",
    "        - screen_pos: Screen positions in shape (17, 10, 2) obtained from calibration (from 80x80 pixel checker corners on a 1280x720px screen)\n",
    "        - xnew: New pixels indexes in x, in interval [0, 17[\n",
    "        - ynew: New pixels indexes in y, in interval [0, 10[\n",
    "    return:\n",
    "        - Screen positions in shape (len(xnew),len(ynew), 2)\n",
    "    \"\"\"\n",
    "    f = interpolate.interp2d(np.arange(17), np.arange(10), screen_pos[:,:,0].T, kind=kind)\n",
    "    znew_x = f(xnew, ynew)\n",
    "\n",
    "    f = interpolate.interp2d(np.arange(17), np.arange(10), screen_pos[:,:,1].T, kind=kind)\n",
    "    znew_y = f(xnew, ynew)\n",
    "\n",
    "    return np.stack((znew_x, znew_y), axis=-1)\n",
    "\n",
    "def interpolate_checker_pos(screen_pos, width_box, height_box, kind='linear'):\n",
    "    \"\"\"\n",
    "    Interpolate the centre of the checkerboard pixels from the screen calibrated position.\n",
    "    params:\n",
    "        - screen_pos: Screen positions in shape (17, 10, 2) obtained from calibration (from 80x80 pixel checker corners on a 1280x720px screen)\n",
    "        - width_box: Width in pixel of a box\n",
    "        - height_box: Height in pixel of a box\n",
    "        - kind: kind of interpolation in {'linear', 'cubic', 'quintic'}\n",
    "    \"\"\"\n",
    "    assert 1280%width_box==0, \"unpredictable behaviour if 1280 is not a multiple of width_box\"\n",
    "    assert 720%height_box==0, \"unpredictable behaviour if 720 is not a multiple of height_box\"\n",
    "    n_x = 1280/width_box\n",
    "    n_y = 720/height_box\n",
    "    xnew = np.arange(16/n_x/2, 16+16/n_x/2, 16/n_x)\n",
    "    ynew = np.arange(9/n_y/2, 9+9/n_y/2, 9/n_y)\n",
    "    return interpolate_screen_pos(screen_pos, xnew, ynew, kind=kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def split_eye_events(eye_tracking, eps=2):\n",
    "    \"\"\"\n",
    "    Split the record where the eye moves. Detection done with clustering on X,Y and time of the eye position.\n",
    "    \n",
    "    params:\n",
    "        - eye_tracking: Eye traking array of the ellipse fit, in shape (t, (x,y,width,height,angle))\n",
    "        - eps: Distance to detect eye movements. Adjust this parameter if results are not satisfying\n",
    "        - kind: kind of interpolation in {'linear', 'cubic', 'quintic'}\n",
    "    return:\n",
    "        - move_indexes, blink_indexes, noise_indexes\n",
    "    \"\"\"    \n",
    "    x_pos    = np.array(eye_tracking[:,0])\n",
    "    \n",
    "    X        = np.stack((x_pos, np.linspace(0, len(x_pos), len(x_pos))*.5)).T\n",
    "    clusters = cluster.dbscan(X, eps=eps, min_samples=5, metric='minkowski', p=2)\n",
    "    move_indexes = np.where(clusters[1][1:] > clusters[1][:-1])[0] + 1\n",
    "    \n",
    "    noise_indexes = np.where(clusters[1] == -1)[0]\n",
    "    blink_indexes = np.where(x_pos == 0)[0]\n",
    "\n",
    "    return move_indexes, blink_indexes, noise_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def get_spherical_map(screen_pos, input_res=(281, 500), output_res=(360, 640), k_side=2):\n",
    "    \"\"\"\n",
    "    Generate the mapping from normal image to an image projected on a spherical screen\n",
    "    params:\n",
    "        - screen_pos: Screen positions in shape (17, 10, (elev, azim)) obtained from calibration (from 80x80 pixel checker corners on a 1280x720px screen)\n",
    "        - input_res: resolution of the input image\n",
    "        - output_res: resolution of the output image\n",
    "        - k_side: Kernel side's size to fill holes in the mapped image (2 -> 5*5 kernel)\n",
    "    returns:\n",
    "        - A mapping to be used in `apply_spherical_map`\n",
    "    \"\"\"\n",
    "    screen_interp = interpolate_screen_pos(screen_pos, np.linspace(0,16, input_res[1], endpoint=True), \n",
    "                                                       np.linspace(0, 9, input_res[0], endpoint=True))\n",
    "    y_inres, x_inres = input_res\n",
    "    y_res, x_res     = output_res\n",
    "    xnew = np.linspace(screen_interp[:,:,1].min(), screen_interp[:,:,1].max(), x_res)\n",
    "    ynew = np.linspace(screen_interp[:,:,0].min(), screen_interp[:,:,0].max(), y_res)\n",
    "    map_img = np.zeros((y_res, x_res))\n",
    "    \n",
    "    y_map, x_map = np.empty(y_inres*x_inres, dtype=int), np.empty(y_inres*x_inres, dtype=int)\n",
    "    for i, (y, x) in enumerate(zip(screen_interp[:,::-1,0].flatten(), screen_interp[:,::-1,1].flatten())):\n",
    "        y_map[i] = np.argmin(ynew<y)\n",
    "        x_map[i] = np.argmin(xnew<x)\n",
    "    map_img[y_map, x_map] = 1\n",
    "    \n",
    "    y_nonzero, x_nonzero = np.nonzero(map_img==0) #Finds where the image is still zero\n",
    "    fill_x_l, fill_y_l, nonzeros_l = [], [], []\n",
    "    for y, x in zip(y_nonzero, x_nonzero):\n",
    "        # Sets the limits to where to look for nonzeros pixels\n",
    "        ylow, xlow = max(0, y-k_side), max(0, x-k_side)\n",
    "        yhig, xhig = min(y+k_side+1, y_res), min(x+k_side+1, x_res)\n",
    "        area = map_img[ylow:yhig, xlow:xhig]\n",
    "\n",
    "        if np.any(area): #If there are pixels around\n",
    "            fill_x_l.append(x)\n",
    "            fill_y_l.append(y)\n",
    "            nonz_y, nonz_x = np.nonzero(area)\n",
    "            nonzeros_l.append((nonz_y+ylow, nonz_x+xlow)) #store the nonzero slicing for later filling\n",
    "            \n",
    "    return (y_map, x_map), (fill_y_l, fill_x_l, nonzeros_l)\n",
    "\n",
    "def apply_spherical_map(img_src, mapping, output_res=(360, 640), f_fill=np.mean):\n",
    "    \"\"\"\n",
    "    Apply a mapping to an input image\n",
    "    params:\n",
    "        - img_src: Source image to transform\n",
    "        - mapping: Mapping obtained from `get_spherical_map`\n",
    "        - output_res: Output resolution. Must match the parameter given to `get_spherical_map`\n",
    "        - f_fill: Function to apply when filling the holes (e.g. np.median, np.mean)\n",
    "    return:\n",
    "        - The transformed image\n",
    "    \"\"\"\n",
    "    (y_map, x_map), (fill_y_l, fill_x_l, nonzeros_l) = mapping\n",
    "    \n",
    "    transfo_img = np.zeros(output_res) + 128\n",
    "    transfo_img[y_map, x_map] = img_src.flatten()\n",
    "\n",
    "    for y, x, nonz in zip(fill_y_l, fill_x_l, nonzeros_l):\n",
    "        transfo_img[y, x] = f_fill(transfo_img[nonz])\n",
    "    return transfo_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-bachelor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_utils.ipynb.\n",
      "Converted 02_processing.ipynb.\n",
      "Converted 03_modelling.ipynb.\n",
      "Converted 04_plotting.ipynb.\n",
      "Converted 05_database.ipynb.\n",
      "Converted 06_eyetrack.ipynb.\n",
      "Converted 10_synchro.io.ipynb.\n",
      "Converted 11_synchro.extracting.ipynb.\n",
      "Converted 12_synchro.processing.ipynb.\n",
      "Converted 13_leddome.ipynb.\n",
      "Converted 99_testdata.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
